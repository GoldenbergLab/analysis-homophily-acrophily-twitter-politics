{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0915819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a79d6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class TwitterDataProcessor:\n",
    "class TwitterDataProcessor:\n",
    "    \"\"\"\n",
    "    The TwitterDataProcessor class takes six parameters:\n",
    "\n",
    "    1. poli_affil: the political affiliation ('left' or 'right') of users for which we wish to run the simulation\n",
    "    2. frac_data: whether we wish to run the simulation on only a fraction of the data.\n",
    "    3. frac_start: the starting percentage of users (in decimal form) if frac_data set to True\n",
    "    4. frac_end: the ending percentage of users (in decimal form) if frac_data set to True\n",
    "    5. users_file: The users ratings dataset CSV file path.\n",
    "    6. rt_fle: The retweet network dataset CSV file path.\n",
    "\n",
    "    There are three main functions:\n",
    "\n",
    "    1. load_raw_data: This function loads the raw data for both the users ratings and retweet network datasets.\n",
    "    2. preprocess_data: This function performs the following preprocessing steps for the data:\n",
    "        - It subsets the users dataframe based on the chosen political affiliation on which to run the simulation.\n",
    "        - It filters out both egos and peers with original tweet counts of less than 5 in both dataframes.\n",
    "        - It filters out cases where egos retweeted themselves in the retweet dataframe.\n",
    "        - It subsets down to the chosen fraction of users (if frac_data set to True) in the retweet dataframe.\n",
    "    3. join_data: This function joins the users ratings dataset with the retweet dataset and suffixes to\n",
    "    distinguish between ego and peer ratings.\n",
    "\n",
    "    The main function get_retweet_data calls these functions in succession to create the final dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, poli_affil, frac_data=False, frac_start=None, frac_end=None,\n",
    "                 users_file=os.path.join('..', 'data', 'users_ratings.csv'), \n",
    "                 rt_file=os.path.join('..', 'data', 'rt_network.csv')):\n",
    "\n",
    "        # Initialize political affiliation and data fraction attributes:\n",
    "        self.poli_affil = poli_affil\n",
    "        self.frac_data = frac_data\n",
    "        self.frac_start = frac_start\n",
    "        self.frac_end = frac_end\n",
    "\n",
    "        # Initialize data files:\n",
    "        self.users_file = users_file\n",
    "        self.rt_file = rt_file\n",
    "\n",
    "        # Initializing dataframes:\n",
    "        self.users_df = pd.DataFrame()\n",
    "        self.rt_df = pd.DataFrame()\n",
    "\n",
    "    # Function to load raw data:\n",
    "    def load_raw_data(self):\n",
    "\n",
    "        print('Loading unprocessed user rating and retweet network datasets.', flush=True)\n",
    "\n",
    "        # Load user ratings dataframe if file path exists:\n",
    "        if os.path.exists(self.users_file):\n",
    "            self.users_df = pd.read_csv(self.users_file)\n",
    "            self.users_df = self.users_df.set_index('userid')\n",
    "        else:\n",
    "            return 'Users ratings file does not exist.'\n",
    "\n",
    "        # Define retweet network dataframe if file path exists:\n",
    "        if os.path.exists(self.rt_file):\n",
    "            self.rt_df = pd.read_csv(self.rt_file)\n",
    "\n",
    "        print('Datasets loaded. Processing and joining datasets.', flush=True)\n",
    "\n",
    "    # Function to preprocess loaded raw data:\n",
    "    def preprocess_data(self, min_tweets=5):\n",
    "\n",
    "        # Subset to conservative ego ratings:\n",
    "        if self.poli_affil == 'right':\n",
    "            self.users_df = self.users_df[self.users_df['orig_rating'] > 0]\n",
    "\n",
    "        # Subset to liberal ego ratings and convert ratings to positive scale:\n",
    "        elif self.poli_affil == 'left':\n",
    "            self.users_df = self.users_df[self.users_df['orig_rating'] < 0]\n",
    "            self.users_df['orig_rating'] = self.users_df['orig_rating'] * -1\n",
    "\n",
    "        # Subset based on min tweet threshold:\n",
    "        self.users_df = self.users_df[self.users_df['orig_total_count'] >= min_tweets]\n",
    "\n",
    "        # Subset retweet network ID to contain only egos and peers that meet min tweet threshold:\n",
    "        userid_condition = self.rt_df['userid'].isin(self.users_df.index)\n",
    "        rt_userid_condition = self.rt_df['rt_userid'].isin(self.users_df.index)\n",
    "        self.rt_df = self.rt_df[userid_condition & rt_userid_condition]\n",
    "\n",
    "        # Remove observations where user retweeted self\n",
    "        self.rt_df = self.rt_df[self.rt_df['userid'] != self.rt_df['rt_userid']]\n",
    "\n",
    "        # Subset fraction of users if needed to speed up simulation:\n",
    "        if self.frac_data:\n",
    "\n",
    "            # Get unique user ID values:\n",
    "            all_users = np.unique(self.rt_df['userid'].values)\n",
    "\n",
    "            # Subset to specified fraction of users:\n",
    "            n_users_start = int(self.frac_start*len(all_users))\n",
    "            n_users_end = int(len(all_users) * self.frac_end)\n",
    "            users_fraction = all_users[n_users_start:n_users_end]\n",
    "\n",
    "            # Return dataset with only user IDs in specified fraction:\n",
    "            self.rt_df = self.rt_df[self.rt_df['userid'].isin(users_fraction)]\n",
    "\n",
    "    # Function to join dataframes:\n",
    "    def join_data(self):\n",
    "\n",
    "        # Join on user ID and retweet user ID:\n",
    "        self.rt_df = self.rt_df.join(self.users_df[['orig_rating']],\n",
    "                                     on='userid').join(self.users_df[['orig_rating']],\n",
    "                                                       on='rt_userid',\n",
    "                                                       rsuffix='_peer')\\\n",
    "            .rename(columns={'orig_rating': 'orig_rating_ego'})\n",
    "\n",
    "        print('Datasets joined. Data successfully loaded.', flush=True)\n",
    "\n",
    "    # Main function that returns final dataframe:\n",
    "    def get_retweet_data(self):\n",
    "        self.load_raw_data()\n",
    "        self.preprocess_data()\n",
    "        self.join_data()\n",
    "\n",
    "        return self.rt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9565b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading unprocessed user rating and retweet network datasets.\n",
      "Datasets loaded. Processing and joining datasets.\n",
      "Datasets joined. Data successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "rt_df_left = TwitterDataProcessor(poli_affil='left').get_retweet_data()\n",
    "rt_df_left = rt_df_left[rt_df_left['rt'] <= 10]\n",
    "rt_df_left['poli_affil'] = np.repeat('left', len(rt_df_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ad571cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading unprocessed user rating and retweet network datasets.\n",
      "Datasets loaded. Processing and joining datasets.\n",
      "Datasets joined. Data successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "rt_df_right = TwitterDataProcessor(poli_affil='right').get_retweet_data()\n",
    "rt_df_right = rt_df_right[rt_df_right['rt'] <= 10]\n",
    "rt_df_right['poli_affil'] = np.repeat('right', len(rt_df_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd00ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_df_all = pd.concat([rt_df_left, rt_df_right], axis=0)\n",
    "rt_df_all.to_csv('../data/rt_data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2b933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
